{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPARING DATA 4 VISUALIZATION IN TABLEAU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_features(feature_selection, feat_test_values, target_test_values):\n",
    "    \"\"\"\n",
    "    This function is to extract features in order to reduce the number of them.\n",
    "    \n",
    "    :param str feature_selection: Choose which stat use to reduce the features.\n",
    "    :param np.Array feat_test_values: Numpy array with test features.\n",
    "    :param np.Array target_test_values: Numpy array with test target.\n",
    "    :return np.Array: Numpy array with the process done.\n",
    "    \"\"\"\n",
    "    if feature_selection == 'f_classif':\n",
    "        bests = SelectKBest(f_classif, k=20)\n",
    "        feat_test_values = bests.fit_transform(feat_test_values, target_test_values)\n",
    "    elif feature_selection == 'mutual':\n",
    "        bests = SelectKBest(mutual_info_classif, k=20)\n",
    "        feat_test_values = bests.fit_transform(feat_test_values, target_test_values)\n",
    "    else:\n",
    "        feat_test_values = feat_test_values\n",
    "\n",
    "    return feat_test_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_each_difference(num_list, df_):\n",
    "    \"\"\"\n",
    "    This function categorize the shifted columns in Weak Bull o Bear (W. Bull, W. Bear),\n",
    "    Bull or Bear and Strong Bull or Bear (S. Bull, S. Bear) depending on the value of the shifted column and\n",
    "    his statistics (median, p25, p75) by ticker, year, month and sign.\n",
    "\n",
    "    :param list num_list: List with days to categorize.\n",
    "    :param pd.DataFrame df_: Dataframe to categorize.\n",
    "    :return pd.DataFrame: Dataframe recalculated.\n",
    "    \"\"\"\n",
    "    cols_to_keep = list(df_.columns)\n",
    "    df_['year'], df_['month'] = df_['date'].dt.year, df_['date'].dt.month\n",
    "    for num_ in num_list:\n",
    "        df_.loc[df_['close_shifted_%i' % num_] >= 0, 'sign_%i' % num_] = 'Bull'\n",
    "        df_.loc[df_['close_shifted_%i' % num_] < 0, 'sign_%i' % num_] = 'Bear'\n",
    "        group = df_.groupby(['ticker', 'year', 'month', 'sign_%i' % num_])['close_shifted_%i' % num_].describe()\n",
    "        group = group[['25%', '50%', '75%', 'std']].reset_index()\n",
    "        group.rename({'std': 'std_%i' % num_,\n",
    "                      '25%': '25_%i' % num_,\n",
    "                      '50%': '50_%i' % num_,\n",
    "                      '75%': '75_%i' % num_}, axis='columns', inplace=True)\n",
    "        df_ = pd.merge(left=df_, right=group, on=['ticker', 'year', 'month', 'sign_%i' % num_], how='inner')\n",
    "\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') &\n",
    "                (df_['close_shifted_%i' % num_] <= df_['50_%i' % num_]), 'cat_close_shifted_%i' % num_] = 'W. ' + df_[\n",
    "            'sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') &\n",
    "                (df_['close_shifted_%i' % num_] > df_['50_%i' % num_]) &\n",
    "                (df_['close_shifted_%i' % num_] < df_['75_%i' % num_]), 'cat_close_shifted_%i' % num_] = df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') &\n",
    "                (df_['close_shifted_%i' % num_] >= df_['75_%i' % num_]), 'cat_close_shifted_%i' % num_] = 'S. ' + df_[\n",
    "            'sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') &\n",
    "                (df_['close_shifted_%i' % num_] >= df_['50_%i' % num_]), 'cat_close_shifted_%i' % num_] = 'W. ' + df_[\n",
    "            'sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') &\n",
    "                (df_['close_shifted_%i' % num_] < df_['50_%i' % num_]) &\n",
    "                (df_['close_shifted_%i' % num_] > df_['25_%i' % num_]), 'cat_close_shifted_%i' % num_] = df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') &\n",
    "                (df_['close_shifted_%i' % num_] <= df_['25_%i' % num_]), 'cat_close_shifted_%i' % num_] = 'S. ' + df_[\n",
    "            'sign_%i' % num_]\n",
    "\n",
    "        cols_to_keep.extend(['cat_close_shifted_%i' % num_, '50_%i' % num_, '75_%i' % num_, '25_%i' % num_])\n",
    "    return df_[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shifts(df_, col_to_shift, new_col, shift):\n",
    "    \"\"\"\n",
    "    This function add shifted columns to data by ticker.\n",
    "\n",
    "    :param pd.DataFrame df_: Dataframe with financial data.\n",
    "    :param str col_to_shift: Column over to create the shift.\n",
    "    :param str new_col: Name of the shifted column.\n",
    "    :param int shift: Days to use as shift.\n",
    "    :return pd.DataFrame: Dataframe with the shift added.\n",
    "    \"\"\"\n",
    "\n",
    "    for id_ in df_['ticker'].unique():\n",
    "        df_by_id = df_[df_['ticker'] == id_]\n",
    "        df_.loc[df_['ticker'] == id_, new_col] = -df_by_id[col_to_shift] + df_by_id[col_to_shift].shift(shift)\n",
    "\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nan_values(df_, to_interpolate):\n",
    "    \"\"\"\n",
    "    Interpolate and extrapolate nan values for numerical columns.\n",
    "\n",
    "    :param pd.DataFrame df_: Dataframe with financial data with NaN values.\n",
    "    :param list to_interpolate: List with columns to interpolate.\n",
    "    :return pd.DataFrame: Dataframe with financial data without NaN values.\n",
    "    \"\"\"\n",
    "\n",
    "    list_df = []\n",
    "    for tick in df_['ticker'].unique():\n",
    "        df_by_ticker = df_[df_['ticker'] == tick]\n",
    "        for col in to_interpolate:\n",
    "            df_by_ticker[col] = df_by_ticker[col].interpolate(method='linear', limit_direction='both')\n",
    "        list_df.append(df_by_ticker)\n",
    "    return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_transform():\n",
    "    \"\"\"\n",
    "    Load and transform categorical and financial data to use in models.\n",
    "\n",
    "    :return pd.DataFrame: Dataframe to use in models.\n",
    "    \"\"\"\n",
    "    df_categorical = pd.read_csv('../data/db_bsm_categorical.csv')\n",
    "    df_financial = pd.read_csv('../data/db_bsm_financial.csv')\n",
    "    df_financial.replace(0, np.NaN, inplace=True)\n",
    "    df_financial_not_nan = interpolate_nan_values(df_financial, ['close', 'volume'])\n",
    "    df_financial_not_nan = df_financial_not_nan.sort_values(['ticker', 'date'], ascending=[True, False])\n",
    "    for num_ in [3, 5, 7, 14, 21]:\n",
    "        df_financial_not_nan = add_shifts(df_financial_not_nan, 'close', 'close_shifted_%i' % num_, num_)\n",
    "\n",
    "    df_financial_not_nan.dropna(subset=['close_shifted_21'], inplace=True)\n",
    "    df_fin_not_nan = interpolate_nan_values(df_financial_not_nan, list(df_financial_not_nan.select_dtypes(float)))\n",
    "    df_fin_not_nan['date'] = pd.to_datetime(df_fin_not_nan['date'])\n",
    "    df_fin_not_nan = df_fin_not_nan[df_fin_not_nan['date'].dt.year >= 2019]\n",
    "    df_final = categorize_each_difference([3, 5, 7, 14, 21], df_fin_not_nan)\n",
    "    df_categorical = df_categorical.dropna()\n",
    "    df_categorical = df_categorical.drop_duplicates(subset=['ticker'], keep='first')\n",
    "    df_final = pd.merge(left=df_final, right=df_categorical, how='inner', on='ticker')\n",
    "    df_final.replace(0, np.NaN, inplace=True)\n",
    "    df_final[df_final.select_dtypes(float).columns] = df_final.select_dtypes(float).astype('float32')\n",
    "    df_final.replace([np.inf, -np.inf], np.NaN, inplace=True)\n",
    "    df_final = df_final.dropna()\n",
    "    df_final[df_final.select_dtypes('float32').columns] = df_final.select_dtypes('float32').astype(float)\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_n_cols(df_, n):\n",
    "    \"\"\"\n",
    "    Get the columns that his time window is less than n days.\n",
    "\n",
    "    :param pd.DataFrame df_: Dataframe with financial data.\n",
    "    :param int n: n days to get columns with.\n",
    "    :return list: List with the name of the columns.\n",
    "    \"\"\"\n",
    "\n",
    "    return [elem for elem in df_.columns if\n",
    "            (re.search(r'\\d+$', elem) is not None) and (int(elem[-2:].strip().strip('_')) < n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unwanted_cols(df_):\n",
    "    \"\"\"\n",
    "    This functions gives columns to drop from df_.\n",
    "\n",
    "    :param pd.DataFrame df_: Dataframe to calc unwanted columns.\n",
    "    :return list: Name of the unwanted columns from df_.\n",
    "    \"\"\"\n",
    "    return [elem for elem in df_.columns if\n",
    "            elem.startswith('close_shifted') or\n",
    "            elem.startswith('cat_close_shifted') or\n",
    "            elem.startswith('std') or\n",
    "            elem.startswith('25') or \n",
    "            elem.startswith('50') or \n",
    "            elem.startswith('75')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\esteb\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%time df_2_proc = load_and_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_keep = ['close','date', 'ticker', 'close_shifted_3', 'close_shifted_5', 'close_shifted_7', 'close_shifted_14', 'close_shifted_21', 'cat_close_shifted_3',\n",
    "                '50_3', '75_3', '25_3', 'cat_close_shifted_5', '50_5', '75_5', '25_5', 'cat_close_shifted_7', '50_7', '75_7', '25_7', 'cat_close_shifted_14', '50_14',\n",
    "                '75_14', '25_14', 'cat_close_shifted_21', '50_21', '75_21', '25_21', 'company', 'sector_gics', 'stock_index', 'country', 'pred_3', 'pred_5', 'pred_7', \n",
    "                'pred_14', 'pred_21']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_preds = []\n",
    "list_preds_df = []\n",
    "feature_selection = 'mutual'\n",
    "for sector_ in list(df_2_proc['sector_gics'].unique()):\n",
    "    for num_ in [3, 5, 7, 14, 21]:\n",
    "        list_to_drop = get_non_n_cols(df_2_proc, num_)\n",
    "        df_ = df_2_proc[df_2_proc['sector_gics'] == sector_]\n",
    "        df_ = df_.drop(list_to_drop, axis='columns')\n",
    "        if (feature_selection == 'f_classif') or (feature_selection == 'mutual'):\n",
    "            path = '../models_%s/%s/%i' % (feature_selection, sector_, num_)\n",
    "        else:\n",
    "            path = '../models/%s/%i' % (sector_, num_)\n",
    "        path = os.path.relpath(path)\n",
    "        list_files = os.listdir(path)\n",
    "        for file in list_files:\n",
    "            if file.endswith('.mdl'):\n",
    "                model_path = os.path.join(path, file)\n",
    "        mdl = joblib.load(model_path)\n",
    "        y_test = df_['cat_close_shifted_%d' % num_]\n",
    "        X_test = df_[df_.select_dtypes(float).columns]\n",
    "        list_to_drop_2 = get_unwanted_cols(X_test)\n",
    "        X_test = X_test.drop(list_to_drop_2, axis='columns')\n",
    "        X_test_values = X_test.values\n",
    "        y_test_values = y_test.values\n",
    "        X_test_values = fit_transform_features(feature_selection, X_test_values, y_test_values)\n",
    "        y_pred = mdl.predict(X_test_values)\n",
    "        y_pred = y_pred.tolist()\n",
    "        y_pred = pd.DataFrame({'pred_%i' % num_: y_pred})\n",
    "        list_preds.append(y_pred)\n",
    "    df_preds = pd.concat(list_preds, axis='columns')\n",
    "    list_preds = []\n",
    "    df_filtered = df_2_proc[df_2_proc['sector_gics'] == sector_].reset_index(drop=True)\n",
    "    df_tot = pd.concat([df_filtered, df_preds], axis='columns')\n",
    "    df_tot = df_tot[cols_to_keep]\n",
    "    list_preds_df.append(df_tot)\n",
    "df_fin = pd.concat(list_preds_df, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_ in [3, 5, 7, 14, 21]:\n",
    "    df_fin['ccs_%i_abs' % num_] = df_fin['cat_close_shifted_%i' % num_].apply(lambda _: _[-4:])\n",
    "    df_fin['ccs_%i_pred' % num_] = df_fin['pred_%i' % num_].apply(lambda _: _[-4:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (feature_selection == 'f_classif') or (feature_selection == 'mutual'):\n",
    "    path_to_save = '../data/4vis_%s.csv' % feature_selection\n",
    "else:\n",
    "    path_to_save = '../data/4vis.csv'\n",
    "df_fin.to_csv(path_to_save, index=False, sep=';', decimal=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2348, 47)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
