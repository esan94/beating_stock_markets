{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sbn\n",
    "import re\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import RobustScaler, OneHotEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shifts(df_, col_to_shift, new_col, shift):\n",
    "    \"\"\"\n",
    "    This function add shifted columns to data by ticker.\n",
    "    \n",
    "    :param pd.DataFrame df_: Dataframe with financial data.\n",
    "    :param str col_to_shift: Column over to create the shift.\n",
    "    :param str new_col: Name of the shifted column.\n",
    "    :param int shift: Days to use as shift.\n",
    "    :return pd.DataFrame: Dataframe with the shift added.\n",
    "    \"\"\"\n",
    "    \n",
    "    for id_ in df_['ticker'].unique():\n",
    "        df_by_id = df_[df_['ticker'] == id_]\n",
    "        df_.loc[df_['ticker'] == id_, new_col] = df_by_id[col_to_shift] - df_by_id[col_to_shift].shift(shift)\n",
    "        \n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_non_n_cols(df_, n):\n",
    "    \"\"\"\n",
    "    Get the columns that his window is not n days\n",
    "    \n",
    "    :param pd.DataFrame df_: Dataframe with financial data.\n",
    "    :param int n: n days to get columns with.\n",
    "    :return list: List with the name of the columns.\n",
    "    \"\"\"\n",
    "    \n",
    "    return [elem for elem in df_.columns if (re.search(r'\\d+$', elem) is not None) and (int(elem[-2:].strip()) != n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate_nan_values(df_, to_interpolate):\n",
    "    \"\"\"\n",
    "    Interpolate and extrapolate nan values for numerical columns.\n",
    "    \n",
    "    :param pd.DataFrame df_: Dataframe with financial data with NaN values.\n",
    "    :param list to_interpolate: List with columns to interpolate.\n",
    "    :return pd.DataFrame: Dataframe with financial data without NaN values.\n",
    "    \"\"\"\n",
    "    \n",
    "    list_df = []\n",
    "    for tick in df_['ticker'].unique():\n",
    "        df_by_ticker = df_[df_['ticker'] == tick]\n",
    "        for col in to_interpolate:\n",
    "            df_by_ticker[col] = df_by_ticker[col].interpolate(method='linear', limit_direction='both')\n",
    "        list_df.append(df_by_ticker)\n",
    "    return pd.concat(list_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_each_difference(num_list, df_):\n",
    "    \"\"\"\n",
    "    This function categorize the shifted columns in Weak Bull o Bear (W. Bull, W. Bear), \n",
    "    Bull or Bear and Strong Bull or Bear (S. Bull, S. Bear) depending on the value of the shifted column and\n",
    "    his statistics (median, p25, p75) by ticker, year, month and sign.\n",
    "    \n",
    "    :param list num_list: List with days to categorize.\n",
    "    :param pd.DataFrame df_: Dataframe to categorize.\n",
    "    :return pd.DataFrame: Dataframe recalculated.\n",
    "    \"\"\"\n",
    "    cols_to_keep = list(df_.columns)\n",
    "    df_['year'], df_['month'] = df_['date'].dt.year, df_['date'].dt.month\n",
    "    for num_ in num_list:\n",
    "        df_.loc[df_['close_shifted_%i' % num_] >= 0, 'sign_%i' % num_] = 'Bull'\n",
    "        df_.loc[df_['close_shifted_%i' % num_] < 0, 'sign_%i' % num_] = 'Bear'\n",
    "        group = df_.groupby(['ticker', 'year', 'month', 'sign_%i' % num_])['close_shifted_%i' % num_].describe()\n",
    "        group = group[['25%', '50%', '75%', 'std']].reset_index()\n",
    "        group.rename({'std': 'std_%i' % num_}, axis='columns', inplace=True)\n",
    "        df_ = pd.merge(left=df_, right=group, on=['ticker', 'year', 'month', 'sign_%i' % num_], how='inner')\n",
    "        \n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') & \n",
    "                (df_['close_shifted_%i' % num_] <= df_['50%']), 'cat_close_shifted_%i' % num_] = 'W. ' + df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') & \n",
    "                   (df_['close_shifted_%i' % num_] > df_['50%']) &\n",
    "                   (df_['close_shifted_%i' % num_] < df_['75%']), 'cat_close_shifted_%i' % num_] = df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bull') &\n",
    "                   (df_['close_shifted_%i' % num_] >= df_['75%']), 'cat_close_shifted_%i' % num_] = 'S. ' + df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') & \n",
    "                (df_['close_shifted_%i' % num_] >= df_['50%']), 'cat_close_shifted_%i' % num_] = 'W. ' + df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') & \n",
    "                   (df_['close_shifted_%i' % num_] < df_['50%']) &\n",
    "                   (df_['close_shifted_%i' % num_] > df_['25%']), 'cat_close_shifted_%i' % num_] = df_['sign_%i' % num_]\n",
    "        df_.loc[(df_['sign_%i' % num_] == 'Bear') & \n",
    "                   (df_['close_shifted_%i' % num_] <= df_['25%']), 'cat_close_shifted_%i' % num_] = 'S. ' + df_['sign_%i' % num_]\n",
    "        \n",
    "        df_.drop(['25%', '50%', '75%'], axis='columns', inplace=True)\n",
    "        cols_to_keep.extend(['cat_close_shifted_%i' % num_, 'std_%i' % num_])\n",
    "    return df_[cols_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = pd.read_csv('../data/db_bsm_categorical.csv')\n",
    "df_financial = pd.read_csv('../data/db_bsm_financial.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>1081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Null Values\n",
       "close          1081\n",
       "volume         1996"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_financial.replace(0, np.NaN, inplace=True)\n",
    "df_financial.isnull().sum().to_frame('Null Values').loc[['close', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_financial_not_nan = interpolate_nan_values(df_financial, ['close', 'volume'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>close</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>volume</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Null Values\n",
       "close             0\n",
       "volume            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_financial_not_nan.isnull().sum().to_frame('Null Values').loc[['close', 'volume']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_list = [3, 5, 7, 14, 21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_ in num_list:\n",
    "    df_fin = add_shifts(df_financial_not_nan, 'close', 'close_shifted_%i' % num_, num_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.dropna(subset=['close_shifted_21'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_not_nan = interpolate_nan_values(df_fin, list(df_fin.select_dtypes(float)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Null Values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADX 14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RSI 21</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROCR 14</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Null Values\n",
       "ADX 14             0\n",
       "RSI 21             0\n",
       "ROCR 14            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin_not_nan.isnull().sum().to_frame('Null Values').sort_values(by='Null Values', ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin_not_nan['date'] = pd.to_datetime(df_fin_not_nan['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 47s\n"
     ]
    }
   ],
   "source": [
    "%time df_final = categorize_each_difference(num_list, df_fin_not_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categorical = df_categorical.dropna()\n",
    "df_categorical = df_categorical.drop_duplicates(subset=['ticker'], keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.merge(left=df_final, right=df_categorical, how='inner', on='ticker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Financials', 'Consumer discretionary', 'Communication services',\n",
       "       'Energy', 'Industrials', 'Healthcare', 'Information technology',\n",
       "       'Consumer staples', 'Utilities'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final['sector_gics'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %time df_final = pd.get_dummies(df_final, columns='sector_gics', prefix='sector_gics_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.loc[df_final['sector_gics'] == 'Utilities', 'sector_gics_Utilities'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Healthcare', 'sector_gics_Heatlhcare'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Financials', 'sector_gics_Financials'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Consumer discretionary', 'sector_gics_Consumer_discretionary'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Communication services', 'sector_gics_Communication_services'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Energy', 'sector_gics_Energy'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Industrials', 'sector_gics_Industrials'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Information technology', 'sector_gics_Information_technology'] = 1\n",
    "df_final.loc[df_final['sector_gics'] == 'Consumer staples', 'sector_gics_Consumer_staples'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final[['sector_gics_Utilities', 'sector_gics_Heatlhcare',\n",
    "          'sector_gics_Financials', 'sector_gics_Consumer_discretionary',\n",
    "          'sector_gics_Communication_services', 'sector_gics_Energy',\n",
    "          'sector_gics_Industrials', 'sector_gics_Information_technology',\n",
    "          'sector_gics_Consumer_staples']] = df_final[['sector_gics_Utilities', 'sector_gics_Heatlhcare',\n",
    "          'sector_gics_Financials', 'sector_gics_Consumer_discretionary',\n",
    "          'sector_gics_Communication_services', 'sector_gics_Energy',\n",
    "          'sector_gics_Industrials', 'sector_gics_Information_technology',\n",
    "          'sector_gics_Consumer_staples']].replace(np.NaN, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_train = df_final[df_final['date'].dt.year < 2019]\n",
    "df_final_test = df_final[df_final['date'].dt.year >= 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Days prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = df_final_train['cat_close_shifted_3']\n",
    "features_train = df_final_train[df_final_train.select_dtypes(float).columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-16a7978fcf7a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mknn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_test' is not defined"
     ]
    }
   ],
   "source": [
    "knn = GridSearchCV(KNeighborsClassifier(),\n",
    "                   param_grid={'n_neighbors': range(4, 12)}, \n",
    "                   scoring='recall_macro', \n",
    "                   cv=3)\n",
    "knn.fit(features_train.values, target_train.values)\n",
    "knn = KNeighborsClassifier(**knn.best_params_)\n",
    "knn.fit(features_train.values, target_train.values)\n",
    "print(classification_report(y_test, knn.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Bear       0.07      0.11      0.08       226\n",
      "        Bull       0.11      0.06      0.07       482\n",
      "     S. Bear       0.13      0.18      0.15       455\n",
      "     S. Bull       0.18      0.14      0.16       725\n",
      "     W. Bear       0.20      0.32      0.25       828\n",
      "     W. Bull       0.34      0.23      0.28      1317\n",
      "\n",
      "   micro avg       0.20      0.20      0.20      4033\n",
      "   macro avg       0.17      0.17      0.17      4033\n",
      "weighted avg       0.22      0.20      0.20      4033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "features_test = df_final_test[df_final_test.select_dtypes(float).columns]\n",
    "target_test = df_final_test['cat_close_shifted_3']\n",
    "print(classification_report(target_test.values, knn.predict(features_test.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
